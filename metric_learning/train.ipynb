{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitposembcondafe902e4f67854e6d98f2a8ceedfcf887",
   "display_name": "Python 3.7.6 64-bit ('pos-emb': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('2.1.0', '2.2.4-tf')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from triplet_preparation import tuples_from_table\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.__version__, tf.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/home/pafrank/Documents/coding/chess-position-embedding/metric_learning/data/samples/lichess_db_standard_rated_2013-01-tuples.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3fe4549654d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/samples/lichess_db_standard_rated_2013-01-tuples.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuples_from_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tuples_0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain_triplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_triplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/coding/chess-position-embedding/metric_learning/triplet_preparation.py\u001b[0m in \u001b[0;36mtuples_from_table\u001b[0;34m(file, table, tuple_indices)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_file_ending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos-emb/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pos-emb/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/home/pafrank/Documents/coding/chess-position-embedding/metric_learning/data/samples/lichess_db_standard_rated_2013-01-tuples.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "'''Test Dataset'''\n",
    "\n",
    "file_path = os.path.abspath('../data/samples/lichess_db_standard_rated_2013-01-tuples.h5')\n",
    "triplets = tuples_from_table(file_path, \"tuples_0\", tuple_indices=[0,1,6])\n",
    "\n",
    "train_triplets, test_triplets = train_test_split(triplets, test_size=0.2, random_state=42)\n",
    "train_triplets.shape, test_triplets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 512)               401920    \n_________________________________________________________________\ndropout (Dropout)            (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "'''Define Model'''\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "\n",
    "# Display the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 1000 samples, validate on 1000 samples\nEpoch 1/10\n 960/1000 [===========================>..] - ETA: 0s - loss: 1.2638 - accuracy: 0.6448\nEpoch 00001: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 1s 653us/sample - loss: 1.2335 - accuracy: 0.6530 - val_loss: 0.7204 - val_accuracy: 0.7850\nEpoch 2/10\n 960/1000 [===========================>..] - ETA: 0s - loss: 0.4300 - accuracy: 0.8792\nEpoch 00002: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 296us/sample - loss: 0.4227 - accuracy: 0.8810 - val_loss: 0.5260 - val_accuracy: 0.8370\nEpoch 3/10\n 864/1000 [========================>.....] - ETA: 0s - loss: 0.3052 - accuracy: 0.9167\nEpoch 00003: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 332us/sample - loss: 0.2916 - accuracy: 0.9230 - val_loss: 0.4594 - val_accuracy: 0.8510\nEpoch 4/10\n 992/1000 [============================>.] - ETA: 0s - loss: 0.1980 - accuracy: 0.9526\nEpoch 00004: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 343us/sample - loss: 0.2001 - accuracy: 0.9520 - val_loss: 0.4495 - val_accuracy: 0.8690\nEpoch 5/10\n 960/1000 [===========================>..] - ETA: 0s - loss: 0.1707 - accuracy: 0.9573\nEpoch 00005: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 308us/sample - loss: 0.1685 - accuracy: 0.9590 - val_loss: 0.4260 - val_accuracy: 0.8600\nEpoch 6/10\n 800/1000 [=======================>......] - ETA: 0s - loss: 0.1080 - accuracy: 0.9850\nEpoch 00006: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 338us/sample - loss: 0.1146 - accuracy: 0.9830 - val_loss: 0.3896 - val_accuracy: 0.8730\nEpoch 7/10\n 864/1000 [========================>.....] - ETA: 0s - loss: 0.0779 - accuracy: 0.9896\nEpoch 00007: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 304us/sample - loss: 0.0774 - accuracy: 0.9890 - val_loss: 0.4030 - val_accuracy: 0.8740\nEpoch 8/10\n 928/1000 [==========================>...] - ETA: 0s - loss: 0.0647 - accuracy: 0.9914\nEpoch 00008: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 298us/sample - loss: 0.0652 - accuracy: 0.9920 - val_loss: 0.4030 - val_accuracy: 0.8650\nEpoch 9/10\n 800/1000 [=======================>......] - ETA: 0s - loss: 0.0492 - accuracy: 0.9962\nEpoch 00009: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 316us/sample - loss: 0.0472 - accuracy: 0.9970 - val_loss: 0.4128 - val_accuracy: 0.8630\nEpoch 10/10\n 832/1000 [=======================>......] - ETA: 0s - loss: 0.0398 - accuracy: 0.9976\nEpoch 00010: saving model to checkpoints/test_cp.ckpt\n1000/1000 [==============================] - 0s 306us/sample - loss: 0.0424 - accuracy: 0.9980 - val_loss: 0.3975 - val_accuracy: 0.8780\n"
    }
   ],
   "source": [
    "'''Create Checkpoints during training'''\n",
    "\n",
    "checkpoint_path = \"checkpoints/test_cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# Train the model with the new callback\n",
    "history = model.fit(train_images, \n",
    "                    train_labels,  \n",
    "                    epochs=10,\n",
    "                    validation_data=(test_images,test_labels),\n",
    "                    callbacks=[cp_callback])  # Pass callback to training\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1a1a187bd0>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "'''Loads the weights from checkpoint path'''\n",
    "model = create_model()\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/pafrank/anaconda3/envs/pos-emb/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: model/test_model/assets\n"
    }
   ],
   "source": [
    "'''Save the complete model after training'''\n",
    "model.save('model/test_model', save_format='tf') # or save_format='h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 512)               401920    \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 407,050\nTrainable params: 407,050\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "'''Load model from saved state'''\n",
    "model = tf.keras.models.load_model('model/test_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1000/1000 - 0s - loss: 0.3975 - accuracy: 0.8780\nRestored model, accuracy: 87.80%\n(1000, 10)\n"
    }
   ],
   "source": [
    "'''Use loaded model for inference'''\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100*acc))\n",
    "print(model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}